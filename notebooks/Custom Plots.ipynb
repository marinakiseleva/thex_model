{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality to combine visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine curves/rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "%matplotlib inline  \n",
    "from models.binary_model.binary_model import BinaryModel\n",
    "from models.ind_model.ind_model import OvAModel\n",
    "from models.multi_model.multi_model import MultiModel\n",
    "\n",
    "from mainmodel.helper_plotting import *\n",
    "\n",
    "mags = [\"g_mag\",  \"r_mag\", \"i_mag\", \"z_mag\", \"y_mag\",\n",
    "        \"W1_mag\", \"W2_mag\",\n",
    "        \"J_mag\", \"K_mag\", \"H_mag\"]\n",
    "\n",
    "\n",
    "exp_dir = \"/Users/marina/Documents/PhD/research/astro_research/experiments/paper_set/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "\n",
    "# Multi \n",
    "multi_model = MultiModel(folds = 10, min_class_size = 40,  \n",
    "                   transform_features = True, cols = mags) \n",
    "multi_model=load_prev_exp(exp_dir, \"multi/Multiclass_Classifier1/\", multi_model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Binary\n",
    "model2 = BinaryModel(folds = 10, min_class_size = 40,  \n",
    "                     transform_features = True, cols = mags) \n",
    "binary_model = load_prev_exp(exp_dir, \"binary/Binary_Classifiers2/\", model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OvA \n",
    "ensemble_model = OvAModel(folds = 10, \n",
    "                  init_from_binary = binary_model,\n",
    "                  min_class_size = 40,  \n",
    "                   transform_features = True, \n",
    "                  cols = mags) \n",
    "import time\n",
    "ensemble_model.results = ensemble_model.run_cfv(time.time())\n",
    "# ensemble_model.range_metrics = ensemble_model.compute_probability_range_metrics(\n",
    "#         ensemble_model.results, bin_size=0.2)\n",
    "# ensemble_model.range_metrics_10 = ensemble_model.compute_probability_range_metrics(\n",
    "#         ensemble_model.results, bin_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ensemble_model.visualize_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot prob metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# matplotlib.font_manager.fontManager.ttflist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "m = ensemble_model\n",
    "\n",
    "# Replot metrics\n",
    "N = m.num_runs if m.num_runs is not None else m.num_folds\n",
    "pc_per_trial = m.get_pc_per_trial(m.results)\n",
    "ps, cs = m.get_avg_pc(pc_per_trial, N)\n",
    "\n",
    "m.plot_all_metrics(ps, cs, pc_per_trial, m.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot prob rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_model.class_prob_rates[\"Unspecified II\"]\n",
    "model = multi_model\n",
    "for class_name in model.class_prob_rates.keys():\n",
    "    rates=model.class_prob_rates[class_name]\n",
    "    a=(rates[0]+rates[1])/2\n",
    "    b=(rates[2]+rates[3])/2\n",
    "    c=(rates[4]+rates[5])/2\n",
    "    d=(rates[6]+rates[7])/2\n",
    "    e=(rates[8]+rates[9])/2\n",
    "    new_rates = [a,b,c,d,e]\n",
    "    model.class_prob_rates[class_name] = new_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rates_together(binary_model, ensemble_model, multi_model, indices=[0,1,2,3,4,5,6])\n",
    "plot_rates_together(binary_model, ensemble_model, multi_model, indices=[7,8,9,10,11,12,13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GOOD PERFORMING\n",
    "# Ia, Ia-91bg, II, II P, TDE, GRB\n",
    "\n",
    "wanted_classes = [\"Unspecified Ia\", \"Ia-91bg\", \"Unspecified II\", \"II P\", \"TDE\", \"GRB\"]\n",
    "indices= []\n",
    "for index, cn in enumerate(ensemble_model.class_labels):\n",
    "    if cn in wanted_classes:\n",
    "        indices.append(index)\n",
    "indices\n",
    "\n",
    "plot_rates_together(binary_model, ensemble_model, multi_model, indices=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_pc_curves_together(binary_model, ensemble_model, multi_model, indices=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_pc_curves_together(binary_model, ensemble_model, multi_model, indices=[0,1,2,3,4,5,6])\n",
    "plot_pc_curves_together(binary_model, ensemble_model, multi_model, indices=[7,8,9,10,11,12,13])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine purity/comp plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mainmodel.helper_compute import *\n",
    "from thex_data.data_consts import * \n",
    "\n",
    "def get_mets_for_model(model, met_type):\n",
    "    \n",
    "    pc_per_trial = model.get_pc_per_trial(model.results)\n",
    "    ps, cs = model.get_avg_pc(pc_per_trial, model.num_folds)\n",
    "    c_baselines, p_baselines = compute_baselines(\n",
    "            model.class_counts, model.class_labels, model.y, len(model.class_labels), model.class_priors)\n",
    "\n",
    "    p_intvls, c_intvls = compute_confintvls(pc_per_trial, model.class_labels)\n",
    "    if met_type == \"Purity\":\n",
    "#         list(d.values())\n",
    "        return model.class_labels, list(ps.values()), list(p_baselines.values()), list(p_intvls.values())\n",
    "    else:\n",
    "        return model.class_labels, list(cs.values()), list(c_baselines.values()), list(c_intvls.values())\n",
    "         \n",
    "\n",
    "def plot_together(m1, m2, m1_name, m2_name, plot_type = \"Purity\"):\n",
    "    \"\"\"\n",
    "    Plot the metrics of 2 models side by side\n",
    "    \"\"\"\n",
    "    m1_class_names, m1_metrics, m1_b, m1_intvls  = get_mets_for_model(model=m1, met_type=plot_type)\n",
    "    m2_class_names, m2_metrics, m2_b, m2_intvls  = get_mets_for_model(model=m2, met_type=plot_type)\n",
    "    fig, ax = plt.subplots(figsize=(FIG_WIDTH, FIG_HEIGHT), dpi=200,\n",
    "                           tight_layout=True, sharex=True, sharey=True)\n",
    "\n",
    " \n",
    "    BLUE = \"#1f77b4\"\n",
    "    GREEN = \"#00ffbf\"\n",
    "    def plot_m(ax, indices, errs, baselines, metrics, name, color):\n",
    "        bar_width=0.1\n",
    "        ax.barh(y=indices, \n",
    "                width=metrics, \n",
    "                height=bar_width, \n",
    "                xerr=errs,\n",
    "                capsize=2, \n",
    "                edgecolor='black', ecolor='coral', \n",
    "                color=color,\n",
    "                label=name)\n",
    "        for index, baseline in enumerate(baselines):\n",
    "            y_val = indices[index]\n",
    "            plt.vlines(x=baseline,\n",
    "                       ymin=y_val - (bar_width / 2),\n",
    "                       ymax=y_val + (bar_width / 2),\n",
    "                       linestyles='--', colors='red')\n",
    "    m1_errs = prep_err_bars(m1_intvls, m1_metrics) \n",
    "    m1_indices =[0.2, 0.42, 0.64, 0.86]\n",
    "    # with priors\n",
    "    plot_m(ax=ax, indices=m1_indices, errs=m1_errs, baselines=m1_b, \n",
    "           metrics=m1_metrics, color=GREEN, name=m1_name)\n",
    "    m2_errs = prep_err_bars(m2_intvls, m2_metrics)\n",
    "    plot_m(ax=ax, indices=[0.1, 0.32, 0.54, 0.76], errs=m2_errs, baselines=m2_b, \n",
    "           metrics=m2_metrics, color=BLUE, name=m2_name)\n",
    "\n",
    "    # Figure formatting\n",
    "    ax.set_xlim(0, 1)\n",
    "    plt.legend(fontsize=LAB_S)\n",
    "    plt.xticks(list(np.linspace(0, 1, 11)), [\n",
    "                       str(tick) + \"%\" for tick in list(range(0, 110, 10))], fontsize=TICK_S)\n",
    "    plt.yticks(np.array(m1_indices) - 0.05, clean_class_names(m1_class_names),  fontsize=TICK_S+3,\n",
    "                       horizontalalignment='right')\n",
    "#     plt.ylabel('Transient Class', fontsize=LAB_S)\n",
    "    plt.xlabel(plot_type, fontsize=LAB_S+1)  \n",
    "#     plt.title(plot_type, fontsize=TITLE_S)\n",
    "    plt.savefig(\"../output/custom_figures/prior_comp_combined_\" + plot_type + \".pdf\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prev_exp(expnum, model):\n",
    "    exp_dir = \"/Users/marina/Documents/PhD/research/astro_research/experiments/paper_set/\" \n",
    "    pickle_dir = exp_dir + expnum + \"/\"\n",
    "\n",
    "    with open(pickle_dir + 'results.pickle', 'rb') as handle:\n",
    "        results = pickle.load(handle)\n",
    "    model.results = results\n",
    "\n",
    "    with open(pickle_dir + 'y.pickle', 'rb') as handle:\n",
    "        y = pickle.load(handle)\n",
    "    model.y = y\n",
    "    return model\n",
    "\n",
    "model = MultiModel(folds = 10,\n",
    "                   min_class_size = 40,  \n",
    "                   class_labels = ['Unspecified Ia', 'Unspecified II', 'Ia-91bg', 'TDE'],\n",
    "                   priors = [0.65, 0.36, 0.01, 0.005],\n",
    "                   transform_features = True,\n",
    "                   cols = mags)  \n",
    "multi_w = load_prev_exp(expnum=\"multi_priors/Multiclass_Classifier2/\",model=model)\n",
    "\n",
    "\n",
    "modelwithout = MultiModel(folds = 10,\n",
    "                   min_class_size = 40,  \n",
    "                   class_labels = ['Unspecified Ia', 'Unspecified II', 'Ia-91bg', 'TDE'], \n",
    "                   transform_features = True,\n",
    "                   cols = mags)  \n",
    "multi_wo = load_prev_exp(expnum=\"multi_no_priors/Multiclass_Classifier3/\",model=modelwithout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_together(m1=multi_w, m2=multi_wo, m1_name=\"With priors\", m2_name=\"Without priors\", plot_type = \"Purity\")\n",
    "\n",
    "plot_together(m1=multi_w, m2=multi_wo, m1_name=\"With priors\", m2_name=\"Without priors\", plot_type = \"Completeness\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_w.range_metrics = multi_w.compute_probability_range_metrics(\n",
    "        multi_w.results, bin_size=0.2)\n",
    "multi_wo.range_metrics = multi_wo.compute_probability_range_metrics(\n",
    "        multi_wo.results, bin_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_w.class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from thex_data.data_consts import ROOT_DIR\n",
    "from mainmodel.helper_plotting import *\n",
    "\n",
    "class_labels = multi_w.class_labels\n",
    "num_classes = len(multi_w.class_labels) \n",
    "f, ax = plt.subplots(nrows=num_classes,\n",
    "                     ncols=2,\n",
    "                     sharex=True, sharey=True,\n",
    "                     figsize=(FIG_WIDTH, 8),\n",
    "                     dpi=DPI)\n",
    "plot_index = 0\n",
    "for class_index in range(len(class_labels)):\n",
    "    if plot_index == 0:\n",
    "        # Add titles to top of plots\n",
    "        ax[plot_index][0].set_title(\"With priors\", fontsize=11)\n",
    "        ax[plot_index][1].set_title(\"Without priors\", fontsize=11)\n",
    "\n",
    "    class_name = class_labels[class_index]\n",
    "    print(class_name)\n",
    "    plot_model_rates(class_name, multi_w, ax[plot_index][0])\n",
    "    plot_model_rates(class_name, multi_wo, ax[plot_index][1])\n",
    "\n",
    "    pretty_class_name = clean_class_name(class_name)\n",
    "    ax[plot_index][0].set_ylabel(pretty_class_name, fontsize=9)\n",
    "    plot_index += 1\n",
    "\n",
    "y_indices = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "y_ticks = [\"10%\", \"30%\", \"50%\", \"70%\", \"90%\"]\n",
    "# x and y indices/ticks are the same\n",
    "plt.xticks(np.arange(5), y_ticks)\n",
    "plt.yticks(y_indices, y_ticks)\n",
    "plt.rc('xtick', labelsize=7)\n",
    "plt.rc('ytick', labelsize=7)\n",
    "\n",
    "f.text(0.5, 0.08, 'Assigned Probability' + r' $\\pm$10%', fontsize=10, ha='center')\n",
    "f.text(0.0, .5, 'Empirical Probability',\n",
    "       fontsize=10, va='center', rotation='vertical')\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0.1)\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "\n",
    "f.savefig(ROOT_DIR + \"/output/custom_figures/merged_metrics_priors_comp.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "THEx env (py3env)",
   "language": "python",
   "name": "thexkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
