{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THEx Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section illustrates how to call and run a model in THEx infrastructure. There are three models: the binary classifiers (BinaryModel), the One-Vs-All classifier (that aggregates the binary results, the OvAModel), and the KDE multiclass classifier which creates a unique KDE for each class and normalizes over those likelihoods (MultiModel). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the following parameters the models handle:\n",
    "- __cols__ [default=None] : List of column/feature names to use ; the default is all numeric columns\n",
    "- __col_matches__ [default=None]: An alternative to passing in column names. Here a list of strings may be passed on, and any column containing one of these strings will be used. If both cols and col_matches are set, only col_matches is used \n",
    "- __num_runs__ [default=None]: The number of trials to run and average results over. For each trial, 80% of data will be randomly selected for training, and 20% for testing. \n",
    "- __folds__ [default=None] : The number of folds to run over, in k-fold cross-validation. If both num_runs and folds are passed in, num_runs will be used.\n",
    "- __transform_features__ [default=True]: Derives colors from adjacent magnitudes, using dictionary ORDERED_MAGS in thex_data.data_consts.py\n",
    "- __min_class_size__ [default=9]: Each class must contain at least this number of samples for it to be used. \n",
    "- __max_class_size__ [default=None]: Classes with more than this number of samples will be randomly sampled down to this number\n",
    "- __pca__ [default=None]: Number of components to reduce down to using PCA, by default there is no PCA\n",
    "- __class_labels__ [default=None]: List of classes to limit analysis to. List of all classes is in thex_data.data_consts, ORDERED_CLASSES\n",
    "- __data__ [default=None]: Optional parameter for testing particular sets of data. By default, we collect the data from the file in thex_data.data_consts DATA_PATH file, but this parameter may be used to pass in particular datasets. It must be a list of the training and testing Pandas DataFrames: [train_df, test_df] \n",
    "- __nb__ [default=False]: Boolean on applying Naive Bayes. If True, a unique KDE is created for each dimension. If False, we use multivariate KDE. \n",
    "- __priors__ [default=None]: Prior probabilities to use. If None, no priors are used (uniform priors assumed). Otherwise, a list may be passed in with the prior probability for each class, in the same order as classes are listed in class_labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marina/Documents/PhD/research/astro_research/code/environments/thex_env/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.neighbors.kde module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Multiclass Classifier output to directory /Users/marina/Documents/PhD/research/astro_research/code/thex_model/thex_data/../output/Multiclass_Classifier9\n",
      "\n",
      "\n",
      "Constructing Class Hierarchy Tree...\n",
      "Using data: /Users/marina/Documents/PhD/research/astro_research/code/thex_model/thex_data/../../../data/catalogs/v7/THEx-assembled-v7.1a-mags-legacy-xcalib-minxcal.fits\n",
      "\n",
      "Classes Used:\n",
      "['Unspecified Ia', 'Unspecified ÷II']\n",
      "\n",
      "Features Used:\n",
      "['W2_mag', 'H_mag', 'NUV_mag', 'K_mag', 'FUV_mag', 'W1_mag', 'W4_mag', 'y_mag', 'u_mag', 'z_mag', 'J_mag', 'g_mag', 'i_mag', 'r_mag', 'W3_mag', 'W1_mag_minus_W2_mag', 'J_mag_minus_H_mag', 'FUV_mag_minus_NUV_mag', 'H_mag_minus_K_mag', 'K_mag_minus_W1_mag', 'W3_mag_minus_W4_mag', 'z_mag_minus_y_mag', 'NUV_mag_minus_u_mag', 'i_mag_minus_z_mag', 'y_mag_minus_J_mag', 'u_mag_minus_g_mag', 'r_mag_minus_i_mag', 'g_mag_minus_r_mag', 'W2_mag_minus_W3_mag']\n",
      "\n",
      "\n",
      "\t\tClass Counts\n",
      "Unspecified Ia : 200\n",
      "Unspecified ÷II : 0\n",
      "\n",
      "Running Multiclass Classifier\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2b7aee23827a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m        )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/PhD/research/astro_research/code/thex_model/mainmodel/mainmodel.py\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/y.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PhD/research/astro_research/code/thex_model/mainmodel/mainmodel.py\u001b[0m in \u001b[0;36mvisualize_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mcompleteness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_completeness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mordered_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ordered_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompleteness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PhD/research/astro_research/code/thex_model/thex_data/data_plot.py\u001b[0m in \u001b[0;36mcalculate_completeness\u001b[0;34m(X, y, class_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnum_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mfeatures_completeness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_valid\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mcompletenesses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_completeness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompletenesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "from models.binary_model.binary_model import BinaryModel\n",
    "from models.ind_model.ind_model import OvAModel\n",
    "from models.multi_model.multi_model import MultiModel\n",
    "\n",
    "\n",
    "# mags = [\"g_mag\",  \"r_mag\", \"i_mag\", \"z_mag\", \"y_mag\",\n",
    "#         \"W1_mag\", \"W2_mag\",\n",
    "#         \"J_mag\", \"K_mag\", \"H_mag\"]\n",
    "\n",
    "mags = [\"g_mag\",  \"r_mag\", \"i_mag\", \"z_mag\", \"y_mag\", \"u_mag\",\n",
    "        \"W1_mag\", \"W2_mag\", \"W3_mag\", \"W4_mag\",\n",
    "        \"J_mag\", \"K_mag\", \"H_mag\",\n",
    "        \"NUV_mag\", \"FUV_mag\"]\n",
    "\n",
    "model = MultiModel(\n",
    "       cols = mags,\n",
    "       folds = 3, \n",
    "       min_class_size = 40,  \n",
    "       max_class_size = 200,\n",
    "       class_labels = ['Unspecified Ia', 'Unspecified ÷II'],#, 'Ia-91bg', 'TDE'],\n",
    "#        priors = [0.65, 0.36, 0.01, 0.005],\n",
    "       transform_features = True,\n",
    "        nb = True\n",
    "       )\n",
    " \n",
    "model.run_model()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previous runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Rerun performance visualizations on saved output of model. \n",
    "\n",
    "import pickle\n",
    "def load_prev_exp(expnum, model):\n",
    "    pickle_dir = \"/Users/marina/Documents/PhD/research/astro_research/experiments/\"+ expnum + \"/\"\n",
    "\n",
    "\n",
    "    # with open(pickle_dir + 'density_results.pickle', 'rb') as handle:\n",
    "    #     density_results = pickle.load(handle)  \n",
    "\n",
    "    with open(pickle_dir + 'results.pickle', 'rb') as handle:\n",
    "        results = pickle.load(handle)\n",
    "    model.results = results\n",
    "\n",
    "    with open(pickle_dir + 'y.pickle', 'rb') as handle:\n",
    "        y = pickle.load(handle)    \n",
    "    model.y = y\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "up_model = load_prev_exp(expnum=\"103\",model=model)\n",
    "\n",
    "up_model.visualize_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot example outputs\n",
    "For model with vs. without priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "%matplotlib inline  \n",
    "from models.binary_model.binary_model import BinaryModel\n",
    "from models.ind_model.ind_model import IndModel\n",
    "from models.multi_model.multi_model import MultiModel\n",
    " \n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# Changes from other approach - we do not scale data ; otherwise testing new points is tricky. \n",
    "\n",
    "multi_w = MultiModel(folds = 2,\n",
    "                   min_class_size = 40,  \n",
    "                   class_labels = ['Unspecified Ia', 'Unspecified II', 'Ia-91bg', 'TDE'],\n",
    "                   priors = [0.65, 0.36, 0.01, 0.005],\n",
    "                   transform_features = False,\n",
    "                   cols = mags)  \n",
    "# multi_w = load_prev_exp(expnum=\"106/Multiclass_Classifier13\",model=model)\n",
    "multi_w.run_model()\n",
    "\n",
    "\n",
    "multi_wo = MultiModel(folds = 2,\n",
    "                   min_class_size = 40,  \n",
    "                   class_labels = ['Unspecified Ia', 'Unspecified II', 'Ia-91bg', 'TDE'], \n",
    "                   transform_features = False,\n",
    "                   cols = mags)  \n",
    "# multi_wo = load_prev_exp(expnum=\"107/Multiclass_Classifier15\",model=model)\n",
    "multi_wo.run_model()\n",
    "\n",
    "\n",
    "\n",
    "from thex_data.data_init import collect_data\n",
    "full_data_set=collect_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mainmodel.helper_compute import *\n",
    "from thex_data.data_consts import *\n",
    "import utilities.utilities as thex_utils\n",
    "\n",
    "\n",
    "def plot_example_output(model, row, i=None, priors=None):\n",
    "    \"\"\"\n",
    "    Plots example output for a set of probabilities for a particular host-galaxy\n",
    "    :param row: Numpy array of probabilities in order of self.class_labels and then TARGET_LABEL\n",
    "    :param i: Index of sample\n",
    "    :param priors: Boolean if using priors, for saving\n",
    "    \"\"\"\n",
    "    labels = row[len(row) - 1]\n",
    "    true_class_index = None\n",
    "    for class_index, class_name in enumerate(model.class_labels):\n",
    "        if class_name in thex_utils.convert_str_to_list(labels):\n",
    "            true_class_index = class_index\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(5, 3), dpi=220)\n",
    "\n",
    "    ACC = \"#b3e0ff\"  # actual class color, light blue\n",
    "    DCC = \"#005c99\"  # default class color, dark blue\n",
    "    if priors:\n",
    "        ACC = \"#00ffbf\"  # actual class color, light green\n",
    "        DCC = \"#00664d\"  # default class color, dark green \n",
    "        \n",
    "    colors = [DCC] * len(model.class_labels)\n",
    "    colors[true_class_index] = ACC\n",
    "    probabilities = row[0:len(row) - 1] \n",
    "    x_indices = np.linspace(0,\n",
    "                            len(model.class_labels) * 0.4,\n",
    "                            len(model.class_labels))\n",
    "    ax.bar(x=x_indices, height=probabilities,  width=0.4, color=colors, bottom=-0.01)\n",
    "    print(\"\\n Probs for this sample\")\n",
    "    print(probabilities)\n",
    "\n",
    "    plt.xlabel('Class', fontsize=LAB_S)\n",
    "    pretty_class_names = clean_class_names(model.class_labels)\n",
    "    plt.xticks(x_indices, pretty_class_names, fontsize=TICK_S)\n",
    "    \n",
    "    ax.set_ylim([0, 1])\n",
    "    yticks = np.arange(0,1.2,.2) \n",
    "    plt.yticks(yticks, [str(int(i*100)) + \"%\" for i in yticks], fontsize=TICK_S)\n",
    "    plt.ylabel('Probability Assigned', fontsize=LAB_S)\n",
    "    \n",
    "    f.set_title(i)\n",
    "    plt.show() \n",
    "\n",
    "def get_sample_name(model, sample):\n",
    "#     sample = model.X.iloc[2] \n",
    "    features = list(multi_wo.X)\n",
    "    match_str = None\n",
    "    for feature in features:\n",
    "        \n",
    "        v = full_data_set[full_data_set[feature] == sample[feature]] \n",
    "        n= v['name'].values[0]\n",
    "        if match_str is None:\n",
    "            match_str = n\n",
    "        else:\n",
    "            if match_str != n:\n",
    "                raise ValueError(\"More than 1\")\n",
    "    return match_str\n",
    "\n",
    "def plot_cor_examples(model_with, model_wo, sample_index=None):\n",
    "    \"\"\"\n",
    "    Plot corresponding example outputs, with and without priors\n",
    "    :param row: Numpy array of probabilities in order of self.class_labels and then TARGET_LABEL\n",
    "    :param i: Index of sample\n",
    "    :param priors: Boolean if using priors, for saving\n",
    "    \"\"\" \n",
    "    \n",
    "    \n",
    "    labels = model_with.y.iloc[sample_index]['transient_type']\n",
    "    \n",
    "    true_class_index = None\n",
    "    for class_index, class_name in enumerate(model_with.class_labels):\n",
    "        if class_name in thex_utils.convert_str_to_list(labels):\n",
    "            true_class_index = class_index \n",
    "    f, ax = plt.subplots(nrows=1,\n",
    "                         ncols=2,\n",
    "                         sharex=True, sharey=True,\n",
    "                         figsize=(6, 2),\n",
    "                         dpi=200) \n",
    "    \n",
    "    x_indices = np.linspace(0, len(model_with.class_labels) * 0.4,  len(model_with.class_labels)) \n",
    "    X_example = model_with.X.iloc[sample_index]\n",
    "    model_with_ps = list(model_with.get_class_probabilities(X_example).values())\n",
    "    model_without_ps = list(model_wo.get_class_probabilities(X_example).values())\n",
    "    \n",
    "    plt.rcParams['xtick.labelsize'] = 8.5 \n",
    "    pretty_class_names = clean_class_names(model_wo.class_labels)\n",
    "#     plt.xticks(x_indices, pretty_class_names, rotation=-20)\n",
    "    \n",
    "    ACC = \"#b3e0ff\"  # actual class color, light blue\n",
    "    DCC = \"#005c99\"  # default class color, dark blue\n",
    "    colors = [DCC] * len(model_with.class_labels)\n",
    "    colors[true_class_index] = ACC \n",
    "    ax[0].bar(x=x_indices, height=model_without_ps,  width=0.4, color=colors, bottom=0)\n",
    "    ax[0].set_title(\"Without Priors\", fontsize=10)\n",
    "    \n",
    "    ACC = \"#00ffbf\"  # actual class color, light green\n",
    "    DCC = \"#00664d\"  # default class color, dark green \n",
    "    colors = [DCC] * len(model_with.class_labels)\n",
    "    colors[true_class_index] = ACC \n",
    "    ax[1].bar(x=x_indices, height=model_with_ps,  width=0.4, color=colors, bottom=0)\n",
    "    ax[1].set_title(\"With Priors\", fontsize=10)\n",
    "    ax[0].set_ylim([0, 1])\n",
    "    ax[1].set_ylim([0, 1])\n",
    "    yticks = np.arange(0,1.2,.2) \n",
    "    plt.yticks(yticks, [str(int(i*100)) + \"%\" for i in yticks])\n",
    "    ax[0].set_ylabel('Probability Assigned')\n",
    "    \n",
    "    \n",
    "    n = get_sample_name(model_with, model_with.X.iloc[sample_index])\n",
    "    plt.figtext(0.5, 1, n, ha='center', va='center') \n",
    "    plt.tight_layout()\n",
    "    plt.xticks(x_indices, pretty_class_names)\n",
    "#     plt.gcf().subplots_adjust(top=1.5)\n",
    "    plt.savefig(\"../output/custom_figures/\" + str(sample_index) + \".pdf\",bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_sample(model, priors, sample_index):\n",
    "    X_example = model.X.iloc[sample_index]\n",
    "    y_example = model.y.iloc[sample_index]\n",
    "    # Get probs and convert from map to list \n",
    "    ps = list(model.get_class_probabilities(X_example).values())\n",
    "    r = np.hstack((ps, y_example.values)) # combine w/ label\n",
    "    plot_example_output(model, r, sample_index, priors) \n",
    "\n",
    "def plot_new_samples(model, num_samples, indices, priors):\n",
    "    \"\"\"\n",
    "    Randomly sample from this list and plot examples\n",
    "    :param num_samples: The number of samples to randomly sample\n",
    "    :param indices: all indices for a particular class to sample from\n",
    "    :param priors: Boolean\n",
    "    \"\"\"\n",
    "    rand_indices = np.random.choice(indices, num_samples, replace=False)\n",
    "    for sample_index in rand_indices:\n",
    "        plot_sample(model, priors, sample_index)\n",
    "    return rand_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot examples for each class, first WITHOUT prior\n",
    "\n",
    "# model = multi_wo\n",
    "class_indices_map = {}\n",
    "for cur_class in multi_wo.class_labels:\n",
    "    indices = []\n",
    "    print(\"\\nSampling class: \" + str(cur_class))\n",
    "    for index, row in multi_wo.y.iterrows():\n",
    "        if cur_class in row['transient_type']:\n",
    "            indices.append(index)\n",
    "    rand_indices = np.random.choice(indices, 3, replace=False)\n",
    "    for index in rand_indices:\n",
    "        plot_cor_examples(multi_w, multi_wo, sample_index=index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "THEx env (py3env)",
   "language": "python",
   "name": "thexkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
