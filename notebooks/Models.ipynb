{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THEx Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section illustrates how to call and run a model in THEx infrastructure. There are three models: the binary classifiers (BinaryModel), the One-Vs-All classifier (that aggregates the binary results, the OvAModel), and the KDE multiclass classifier which creates a unique KDE for each class and normalizes over those likelihoods (MultiModel). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the following parameters the models handle:\n",
    "- __cols__ [default=None] : List of column/feature names to use ; the default is all numeric columns\n",
    "- __col_matches__ [default=None]: An alternative to passing in column names. Here a list of strings may be passed on, and any column containing one of these strings will be used. If both cols and col_matches are set, only col_matches is used \n",
    "- __num_runs__ [default=None]: The number of trials to run and average results over. For each trial, 80% of data will be randomly selected for training, and 20% for testing. \n",
    "- __folds__ [default=None] : The number of folds to run over, in k-fold cross-validation. If both num_runs and folds are passed in, num_runs will be used.\n",
    "- __transform_features__ [default=True]: Derives colors from adjacent magnitudes, using dictionary ORDERED_MAGS in thex_data.data_consts.py\n",
    "- __min_class_size__ [default=9]: Each class must contain at least this number of samples for it to be used. \n",
    "- __max_class_size__ [default=None]: Classes with more than this number of samples will be randomly sampled down to this number\n",
    "- __pca__ [default=None]: Number of components to reduce down to using PCA, by default there is no PCA\n",
    "- __class_labels__ [default=None]: List of classes to limit analysis to. List of all classes is in thex_data.data_consts, ORDERED_CLASSES\n",
    "- __data__ [default=None]: Optional parameter for testing particular sets of data. By default, we collect the data from the file in thex_data.data_consts DATA_PATH file, but this parameter may be used to pass in particular datasets. It must be a list of the training and testing Pandas DataFrames: [train_df, test_df] \n",
    "- __nb__ [default=False]: Boolean on applying Naive Bayes. If True, a unique KDE is created for each dimension. If False, we use multivariate KDE. \n",
    "- __priors__ [default=None]: Prior probabilities to use. If None, no priors are used (uniform priors assumed). Otherwise, a list may be passed in with the prior probability for each class, in the same order as classes are listed in class_labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "from models.binary_model.binary_model import BinaryModel\n",
    "from models.ind_model.ind_model import OvAModel\n",
    "from models.multi_model.multi_model import MultiModel\n",
    "\n",
    "\n",
    "mags = [\"g_mag\",  \"r_mag\", \"i_mag\", \"z_mag\", \"y_mag\",\n",
    "        \"W1_mag\", \"W2_mag\",\n",
    "        \"J_mag\", \"K_mag\", \"H_mag\"]\n",
    "\n",
    "# mags = [\"g_mag\",  \"r_mag\", \"i_mag\", \"z_mag\", \"y_mag\", \"u_mag\",\n",
    "#         \"W1_mag\", \"W2_mag\", \"W3_mag\", \"W4_mag\",\n",
    "#         \"J_mag\", \"K_mag\", \"H_mag\",\n",
    "#         \"NUV_mag\", \"FUV_mag\"]\n",
    "\n",
    "model = MultiModel(\n",
    "       cols = mags,\n",
    "       folds = 10,  \n",
    "#        class_labels = ['Unspecified Ia', 'Unspecified II', 'TDE', 'Ia-91bg'],\n",
    "       min_class_size = 40, \n",
    "#        max_class_size =  1000,\n",
    "       transform_features = False\n",
    "       )\n",
    "model.visualize_data()\n",
    "model.run_model() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previous runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Rerun performance visualizations on saved output of model. \n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_dir = \"../../../experiments/paper_set/multi/Multiclass_Classifier1/\"\n",
    "\n",
    "with open(pickle_dir + 'results.pickle', 'rb') as handle:\n",
    "    results = pickle.load(handle)\n",
    "\n",
    "with open(pickle_dir + 'y.pickle', 'rb') as handle:\n",
    "    y = pickle.load(handle)    \n",
    "\n",
    "model.y = y\n",
    "model.results = results\n",
    "# model.visualize_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot example outputs\n",
    "For given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mainmodel.helper_compute import *\n",
    "from thex_data.data_consts import *\n",
    "import utilities.utilities as thex_utils\n",
    "\n",
    "\n",
    "def plot_example_output(model, row, i=None, priors=None):\n",
    "    \"\"\"\n",
    "    Plots example output for a set of probabilities for a particular host-galaxy\n",
    "    :param row: Numpy array of probabilities in order of self.class_labels and then TARGET_LABEL\n",
    "    :param i: Index of sample\n",
    "    :param priors: Boolean if using priors, for saving\n",
    "    \"\"\"\n",
    "    labels = row[len(row) - 1]\n",
    "    true_class_index = None\n",
    "    for class_index, class_name in enumerate(model.class_labels):\n",
    "        if class_name in thex_utils.convert_str_to_list(labels):\n",
    "            true_class_index = class_index\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(5, 3), dpi=220)\n",
    "\n",
    "    ACC = \"#b3e0ff\"  # actual class color, light blue\n",
    "    DCC = \"#005c99\"  # default class color, dark blue\n",
    "    if priors:\n",
    "        ACC = \"#00ffbf\"  # actual class color, light green\n",
    "        DCC = \"#00664d\"  # default class color, dark green \n",
    "        \n",
    "    colors = [DCC] * len(model.class_labels)\n",
    "    colors[true_class_index] = ACC\n",
    "    probabilities = row[0:len(row) - 1] \n",
    "    x_indices = np.linspace(0,\n",
    "                            len(model.class_labels) * 0.4,\n",
    "                            len(model.class_labels))\n",
    "    ax.bar(x=x_indices, height=probabilities,  width=0.4, color=colors, bottom=-0.01)\n",
    "    print(\"\\n Probs for this sample\")\n",
    "    print(probabilities)\n",
    "\n",
    "    plt.xlabel('Class', fontsize=LAB_S)\n",
    "    pretty_class_names = clean_class_names(model.class_labels)\n",
    "    plt.xticks(x_indices, pretty_class_names, fontsize=TICK_S)\n",
    "    \n",
    "    ax.set_ylim([0, 1])\n",
    "    yticks = np.arange(0,1.2,.2) \n",
    "    plt.yticks(yticks, [str(int(i*100)) + \"%\" for i in yticks], fontsize=TICK_S)\n",
    "    plt.ylabel('Probability Assigned', fontsize=LAB_S)\n",
    "    \n",
    "    f.set_title(i)\n",
    "    plt.show() \n",
    "\n",
    "def get_sample_name(model, sample):\n",
    "#     sample = model.X.iloc[2] \n",
    "    features = list(model.X)\n",
    "    match_str = None\n",
    "    for feature in features:\n",
    "        \n",
    "        v = full_data_set[full_data_set[feature] == sample[feature]] \n",
    "        n= v['name'].values[0]\n",
    "        if match_str is None:\n",
    "            match_str = n\n",
    "        else:\n",
    "            if match_str != n:\n",
    "                raise ValueError(\"More than 1\")\n",
    "    return match_str\n",
    "\n",
    "def plot_cor_examples(model_with, model_wo, sample_index=None):\n",
    "    \"\"\"\n",
    "    Plot corresponding example outputs, with and without priors\n",
    "    :param row: Numpy array of probabilities in order of self.class_labels and then TARGET_LABEL\n",
    "    :param i: Index of sample\n",
    "    :param priors: Boolean if using priors, for saving\n",
    "    \"\"\" \n",
    "    \n",
    "    \n",
    "    labels = model_with.y.iloc[sample_index]['transient_type']\n",
    "    \n",
    "    true_class_index = None\n",
    "    for class_index, class_name in enumerate(model_with.class_labels):\n",
    "        if class_name in thex_utils.convert_str_to_list(labels):\n",
    "            true_class_index = class_index \n",
    "    f, ax = plt.subplots(nrows=1,\n",
    "                         ncols=2,\n",
    "                         sharex=True, sharey=True,\n",
    "                         figsize=(6, 2),\n",
    "                         dpi=200) \n",
    "    \n",
    "    x_indices = np.linspace(0, len(model_with.class_labels) * 0.4,  len(model_with.class_labels)) \n",
    "    X_example = model_with.X.iloc[sample_index]\n",
    "    model_with_ps = list(model_with.get_class_probabilities(X_example).values())\n",
    "    model_without_ps = list(model_wo.get_class_probabilities(X_example).values())\n",
    "    \n",
    "    plt.rcParams['xtick.labelsize'] = 8.5 \n",
    "    pretty_class_names = clean_class_names(model_wo.class_labels)\n",
    "#     plt.xticks(x_indices, pretty_class_names, rotation=-20)\n",
    "    \n",
    "    ACC = \"#b3e0ff\"  # actual class color, light blue\n",
    "    DCC = \"#005c99\"  # default class color, dark blue\n",
    "    colors = [DCC] * len(model_with.class_labels)\n",
    "    colors[true_class_index] = ACC \n",
    "    ax[0].bar(x=x_indices, height=model_without_ps,  width=0.4, color=colors, bottom=0)\n",
    "    ax[0].set_title(\"Without Priors\", fontsize=10)\n",
    "    \n",
    "    ACC = \"#00ffbf\"  # actual class color, light green\n",
    "    DCC = \"#00664d\"  # default class color, dark green \n",
    "    colors = [DCC] * len(model_with.class_labels)\n",
    "    colors[true_class_index] = ACC \n",
    "    ax[1].bar(x=x_indices, height=model_with_ps,  width=0.4, color=colors, bottom=0)\n",
    "    ax[1].set_title(\"With Priors\", fontsize=10)\n",
    "    ax[0].set_ylim([0, 1])\n",
    "    ax[1].set_ylim([0, 1])\n",
    "    yticks = np.arange(0,1.2,.2) \n",
    "    plt.yticks(yticks, [str(int(i*100)) + \"%\" for i in yticks])\n",
    "    ax[0].set_ylabel('Probability Assigned')\n",
    "    \n",
    "    \n",
    "    n = get_sample_name(model_with, model_with.X.iloc[sample_index])\n",
    "    plt.figtext(0.5, 1, n, ha='center', va='center') \n",
    "    plt.tight_layout()\n",
    "    plt.xticks(x_indices, pretty_class_names)\n",
    "#     plt.gcf().subplots_adjust(top=1.5)\n",
    "    plt.savefig(\"../output/custom_figures/\" + str(sample_index) + \".pdf\",bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_sample(model, priors, sample_index):\n",
    "    X_example = model.X.iloc[sample_index]\n",
    "    y_example = model.y.iloc[sample_index]\n",
    "    # Get probs and convert from map to list \n",
    "    ps = list(model.get_class_probabilities(X_example).values())\n",
    "    r = np.hstack((ps, y_example.values)) # combine w/ label\n",
    "    plot_example_output(model, r, sample_index, priors) \n",
    "\n",
    "def plot_new_samples(model, num_samples, indices, priors):\n",
    "    \"\"\"\n",
    "    Randomly sample from this list and plot examples\n",
    "    :param num_samples: The number of samples to randomly sample\n",
    "    :param indices: all indices for a particular class to sample from\n",
    "    :param priors: Boolean\n",
    "    \"\"\"\n",
    "    rand_indices = np.random.choice(indices, num_samples, replace=False)\n",
    "    for sample_index in rand_indices:\n",
    "        plot_sample(model, priors, sample_index)\n",
    "    return rand_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.results[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in enumerate(model.results[0]):\n",
    "    if 'GRB' in row[len(model.class_labels)]:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[2,3,3,33]\n",
    "a.reverse()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "b=np.array([2,3,3,33])\n",
    "b.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_index = 733\n",
    "do_index = 800\n",
    "while do_index< 880:\n",
    "    \n",
    "    row = model.results[0][do_index]\n",
    "    # 1015\n",
    "    labels = row[len(row) - 1]\n",
    "    true_class_index = None\n",
    "    for class_index, class_name in enumerate(model.class_labels):\n",
    "        if class_name in thex_utils.convert_str_to_list(labels):\n",
    "            true_class_index = class_index\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(2, 4), dpi=400)\n",
    "\n",
    "    ACC = \"#005c99\"# actual class color, light blue\n",
    "    DCC = \"#b3e0ff\" # default class color, dark blue\n",
    "    # if priors:\n",
    "    #     ACC = \"#00ffbf\"  # actual class color, light green\n",
    "    #     DCC = \"#00664d\"  # default class color, dark green \n",
    "\n",
    "    colors = [DCC] * len(model.class_labels)\n",
    "    colors[true_class_index] = ACC\n",
    "    probabilities = row[0:len(row) - 1] \n",
    "    bar_size = 0.1\n",
    "    x_indices = np.linspace(0,\n",
    "                            len(model.class_labels) * bar_size,\n",
    "                            len(model.class_labels))\n",
    "\n",
    "    # x_list = x_indices.tolist()\n",
    "    # x_list.reverse()\n",
    "    # pretty_class_names.reverse()\n",
    "    # probabilities = probabilities.tolist()\n",
    "    # probabilities.reverse()\n",
    "    # print(x_list)\n",
    "    # print(probabilities)\n",
    "    ax.barh(y=x_indices, width=probabilities,  height=bar_size, color=colors)#, bottom=-0.01)\n",
    "\n",
    "    # plt.xlabel('Class', fontsize=LAB_S)\n",
    "    pretty_class_names = clean_class_names(model.class_labels)\n",
    "    plt.yticks(x_indices, pretty_class_names, fontsize=8)\n",
    "\n",
    "    ax.set_xlim([0, 1])\n",
    "    yticks = np.arange(0,1.2,.2) \n",
    "    plt.xticks(yticks, [str(int(i*100)) + \"%\" for i in yticks], fontsize=9, rotation=-90)\n",
    "    plt.xlabel('Probability', fontsize=10)\n",
    "\n",
    "    # f.set_title(i)\n",
    "    plt.gcf().subplots_adjust(left=0.42)\n",
    "    plt.gcf().subplots_adjust(bottom=0.15)\n",
    "    plt.savefig(\"../output/custom_figures/\" + str(do_index)+\".pdf\")\n",
    "    plt.show() \n",
    "    \n",
    "    do_index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot example outputs\n",
    "For model with vs. without priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "%matplotlib inline  \n",
    "from models.binary_model.binary_model import BinaryModel\n",
    "from models.ind_model.ind_model import IndModel\n",
    "from models.multi_model.multi_model import MultiModel\n",
    " \n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# Changes from other approach - we do not scale data ; otherwise testing new points is tricky. \n",
    "\n",
    "multi_w = MultiModel(folds = 2,\n",
    "                   min_class_size = 40,  \n",
    "                   class_labels = ['Unspecified Ia', 'Unspecified II', 'Ia-91bg', 'TDE'],\n",
    "                   priors = [0.65, 0.36, 0.01, 0.005],\n",
    "                   transform_features = False,\n",
    "                   cols = mags)  \n",
    "# multi_w = load_prev_exp(expnum=\"106/Multiclass_Classifier13\",model=model)\n",
    "multi_w.run_model()\n",
    "\n",
    "\n",
    "multi_wo = MultiModel(folds = 2,\n",
    "                   min_class_size = 40,  \n",
    "                   class_labels = ['Unspecified Ia', 'Unspecified II', 'Ia-91bg', 'TDE'], \n",
    "                   transform_features = False,\n",
    "                   cols = mags)  \n",
    "# multi_wo = load_prev_exp(expnum=\"107/Multiclass_Classifier15\",model=model)\n",
    "multi_wo.run_model()\n",
    "\n",
    "\n",
    "\n",
    "from thex_data.data_init import collect_data\n",
    "full_data_set=collect_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot examples for each class, first WITHOUT prior\n",
    "\n",
    "# model = multi_wo\n",
    "class_indices_map = {}\n",
    "for cur_class in multi_wo.class_labels:\n",
    "    indices = []\n",
    "    print(\"\\nSampling class: \" + str(cur_class))\n",
    "    for index, row in multi_wo.y.iterrows():\n",
    "        if cur_class in row['transient_type']:\n",
    "            indices.append(index)\n",
    "    rand_indices = np.random.choice(indices, 3, replace=False)\n",
    "    for index in rand_indices:\n",
    "        plot_cor_examples(multi_w, multi_wo, sample_index=index) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "THEx env (py3env)",
   "language": "python",
   "name": "thexkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
